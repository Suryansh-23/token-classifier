{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BmSrhDo-nbEx"
      },
      "outputs": [],
      "source": [
        "!pip install huggingface_hub transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HASwaQGbm3Q6"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import notebook_login\n",
        "from transformers import pipeline\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C4jzajgqnfob"
      },
      "outputs": [],
      "source": [
        "classifier = pipeline(\"ner\", model=\"token-classifier/roBERTa-v2\", aggregation_strategy=\"simple\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R9ycfWPYteCs"
      },
      "outputs": [],
      "source": [
        "classifier(\"A user is authenticated by the server using a login and password.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdFEtY8Upvqw"
      },
      "outputs": [],
      "source": [
        "import json, concurrent.futures\n",
        "\n",
        "main = []\n",
        "output = []\n",
        "\n",
        "with open(\"processed\\\\main.json\", encoding=\"utf-8\") as jp:\n",
        "    tmp = json.load(jp)\n",
        "\n",
        "    for i in tmp:\n",
        "        main.append(\" \".join(i[\"tokens\"]))\n",
        "\n",
        "def batch_fn(args):\n",
        "    num, arr = args\n",
        "    idx = 0\n",
        "    print(f\"Batch#{num} running...\")\n",
        "    for i in arr:\n",
        "        print(f\"Batch#{num} @ {idx}...\")\n",
        "\n",
        "        op = classifier(i)\n",
        "        output.append({\"spec\": i, \"extraction\": op})\n",
        "\n",
        "        idx += 1\n",
        "\n",
        "    print(f\"Batch {num} done\")\n",
        "    return\n",
        "\n",
        "output = []\n",
        "divs = 10\n",
        "batches = [(i, i*(len(main)//divs), (i+1)*(len(main)//divs)) for i in range(divs)]\n",
        "\n",
        "executor = concurrent.futures.ThreadPoolExecutor(max_workers=len(batches))\n",
        "list(executor.map(batch_fn, batches))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "myh2xxUh5ySV"
      },
      "outputs": [],
      "source": [
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MojGCfi3FkVX"
      },
      "outputs": [],
      "source": [
        "for i in output:\n",
        "    for j in i[\"extraction\"]:\n",
        "        j[\"score\"] = float(j[\"score\"])\n",
        "\n",
        "with open(\"results.json\", \"w\", encoding=\"utf-8\") as jp:\n",
        "    json.dump(output, jp, indent=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HPmM4BL7GxlS"
      },
      "outputs": [],
      "source": [
        "dist = {\n",
        "    \"no\": 0,\n",
        "    \"class\": 0,\n",
        "    \"method\": 0,\n",
        "    \"attribute\": 0,\n",
        "    \"association\": 0,\n",
        "    \"generalization\": 0,\n",
        "}\n",
        "\n",
        "for i in output:\n",
        "    for j in i[\"extraction\"]:\n",
        "        dist[j[\"entity_group\"]] += 1\n",
        "\n",
        "print(dist)\n",
        "\n",
        "with open(\"extractions.json\", \"w\") as jp:\n",
        "    json.dump(dist, jp, indent=4)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
